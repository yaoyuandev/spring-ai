= ETL Pipeline

The Extract, Transform, and Load (ETL) framework serves as the backbone of data processing within the Retrieval Augmented Generation (RAG) use case.

The ETL pipeline orchestrates the flow from raw data sources to a structured vector store, ensuring data is in the optimal format for retrieval by the AI model.

The RAG use case is text to augment the capabilities of generative models by retrieving relevant information from a body of data to enhance the quality and relevance of the generated output.

== API Overview

=== DocumentReader

Provides a source of documents from diverse origins.
```java
public interface DocumentReader extends Supplier<List<Document>> {

}
```

==== JsonReader
The `JsonReader` Parses documents in JSON format.

Example:

[source,java]
----
@Component
public class MyAiApp {

	@Value("classpath:bikes.json") // This is the json document to load
	private Resource resource;

	List<Document> loadJsonAsDocuments() {
		JsonReader jsonReader = new JsonReader(resource, "description");
		return jsonReader.get();
	}
}
----

==== TextReader
The `TextReader` processes plain text documents.

Example:

[source,java]
----
@Component
public class MyTextReader {

    @Value("classpath:text-source.txt") // This is the text document to load
	private Resource resource;

	List<Document> loadText() {
		TextReader textReader = new TextReader(resource);
		textReader.getCustomMetadata().put("filename", "text-source.txt");

		return textReader.get();
    }
}
----

==== PagePdfDocumentReader
The `PagePdfDocumentReader` uses Apache PdfBox library to parse PDF documents

Example:

[source,java]
----
@Component
public class MyPagePdfDocumentReader {

	List<Document> getDocsFromPdf() {

		PagePdfDocumentReader pdfReader = new PagePdfDocumentReader("classpath:/sample1.pdf",
				PdfDocumentReaderConfig.builder()
					.withPageTopMargin(0)
					.withPageExtractedTextFormatter(ExtractedTextFormatter.builder()
						.withNumberOfTopTextLinesToDelete(0)
						.build())
					.withPagesPerDocument(1)
					.build());

		return pdfReader.get();
    }

}

----


==== ParagraphPdfDocumentReader
The `ParagraphPdfDocumentReader` uses the PDF catalog (e.g. TOC) information to split the input PDF into text paragraphs and output a single `Document` per paragraph.
NOTE: Not all PDF documents contain the PDF catalog.

Example:

[source,java]
----
@Component
public class MyPagePdfDocumentReader {

	List<Document> getDocsFromPdfwithCatalog() {

        new ParagraphPdfDocumentReader("classpath:/sample1.pdf",
                PdfDocumentReaderConfig.builder()
                    .withPageTopMargin(0)
                    .withPageExtractedTextFormatter(ExtractedTextFormatter.builder()
                        .withNumberOfTopTextLinesToDelete(0)
                        .build())
                    .withPagesPerDocument(1)
                    .build());

		return pdfReader.get();
    }
}
----


==== TikaDocumentReader
The `TikaDocumentReader` uses Apache Tika to extract text from a variety of document formats, such as PDF, DOC/DOCX, PPT/PPTX, and HTML. For a comprehensive list of supported formats, refer to the  https://tika.apache.org/2.9.0/formats.html[Tika documentation].

Example:

[source,java]
----
@Component
public class MyTikaDocumentReader {

    @Value("classpath:/word-sample.docx") // This is the word document to load
	private Resource resource;

	List<Document> loadText() {
        TikaDocumentReader tikaDocumentReader = new TikaDocumentReader(resourceUri);
        return tikaDocumentReader.get();
    }
}
----

=== DocumentTransformer

Transforms a batch of documents as part of the processing workflow.

[source,java]
----
public interface DocumentTransformer extends Function<List<Document>, List<Document>> {

}
----

==== TextSplitter
The `TextSplitter` an abstract base class that helps divides documents to fit the AI model's context window.


==== TokenTextSplitter
Splits documents while preserving token-level integrity.

==== ContentFormatTransformer*::
Ensures uniform content formats across all documents.

==== KeywordMetadataEnricher*::
Augments documents with essential keyword metadata.

==== SummaryMetadataEnricher*::
Enriches documents with summarization metadata for enhanced retrieval.

=== DocumentWriter

Manages the final stage of the ETL process, preparing documents for storage.

```java
public interface DocumentWriter extends Consumer<List<Document>> {

}
```

== Available Implementations

There is an implementation for each of the Vector Stores that Spring AI supports, e.g. `PineconeVectorStore`.

See xref:api/vectordbs.adoc[Vector DB Documentation] for a full listing.
